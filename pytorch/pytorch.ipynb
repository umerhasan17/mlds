{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on Pytorch\n",
    "\n",
    "* The forward function in feed-forward nn can be really complicated to account for numerous tasks to be executed by neural network. It is really simple in pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch is just numpy on a GPU\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.,  3.])\n"
     ]
    }
   ],
   "source": [
    "# tensor is a multi-dimensional array\n",
    "x = torch.Tensor([5, 3])\n",
    "y = torch.Tensor([2, 1])\n",
    "\n",
    "print(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5])\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros([2, 5])\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape = view\n",
    "y.view([1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"\", train=True, download=True, \n",
    "                       transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST(\"\", train=False, download=True,\n",
    "                      transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([4, 2, 0, 7, 0, 1, 1, 3, 3, 5])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = data[0][0], data[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# shape is 1x28x28 not 28 28 so modify to show the image\n",
    "print(data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6620107390>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[0][0].view(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# feed forward NN\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # very important\n",
    "        inputNum = 28 * 28\n",
    "        layersNum = 64\n",
    "        outputNum = 10\n",
    "        self.fc1 = nn.Linear(inputNum, layersNum)\n",
    "        self.fc2 = nn.Linear(layersNum, layersNum)\n",
    "        self.fc3 = nn.Linear(layersNum, layersNum)\n",
    "        self.fc4 = nn.Linear(layersNum, outputNum)\n",
    "        \n",
    "    # this forward function can be a lot more complicated with conditional branches\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        # constrains to 1 digit to light up or probability distribution\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3608, -2.2482, -2.3990, -2.2252, -2.3281, -2.2159, -2.4503, -2.1692,\n",
       "         -2.2882, -2.3784]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(28, 28)\n",
    "X = X.view(-1, 28*28)\n",
    "output = net(X)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0456, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0044, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0070, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# TODO: need to decay the learning rate for more accurate models\n",
    "optimiser = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# full passes through dataset\n",
    "EPOCHS = 3\n",
    "\n",
    "# ignite library for this training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        # can use mean square error for 1 hot vector\n",
    "        loss = F.nll_loss(output, y)\n",
    "        # backpropogate\n",
    "        loss.backward()\n",
    "        # adjust weights\n",
    "        optimiser.step()\n",
    "    print(loss)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.98\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "        \n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[index].view(28, 28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6)\n"
     ]
    }
   ],
   "source": [
    "# model just keeps predicting 6?\n",
    "print(torch.argmax(net(X[index].view(-1, 28*28))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
